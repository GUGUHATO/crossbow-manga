# 朗读模块

包含离线朗读器pyttsx3（微软）和在线朗读器gtts（谷歌娘），不确定中国大陆能否访问谷歌娘，所以附加了一个离线版。

## 实现备注

前后端实现了通用接口，理论上朗读器应该是返回一个二进制流，然后前端播放它。但是因为pyttsx3看了一眼源码，里面的流操作非常神秘，不太容易直接导出，如果想获得流的话只能保存到文件系统，然后再读取这个文件，属实是有点low了。所以最后干脆用更直接的方式，pyttsx3直接在python里面播放就完事了，也不用传回前端了。接口仍然被正常调用，但是返回的是空文件。谷歌娘这边就各方面比较正常了。

注：pyttsx3调用的是windows系统的朗读接口，如果想使用的话需要支持日文语言包（输入法，语音等等），你需要在系统设置里启用。

## 技术讨论

谷歌娘和微软win内置的这些朗读都是比较原始的技术了，读起来也蛮生硬，只能说聊胜于无。我不是做音频转换相关方向的，不过查了一下比较新的成果似乎GAN用来做生成已经能做到相当不错的效果了。

比较不错的有微软的Azure，朗读已经十分接近于真实人类，测试的时候用播音腔播新闻简直让我听不出是机器人哈哈。只不过这个服务如果想编程化调用的话还需要注册一个平台账号然后申请自己的访问key，我感觉太麻烦了，因为我们软件的设计目的是解决实际问题，要向非开发人员普及，类似的申请流程应该越少越好。还有一种获取的方式是edge浏览器自带Azure的朗读，但是不太懂怎么调用，分明电脑上已经有对应的软件，但是不给用，实在很气。

另外自训练模型相关，github浏览的过程中查到一个叫tacotron2的模型很火，听了一下效果也非常不错，英伟达似乎还开源了一个预训练库，再加之训练语料非常容易获取（Galgame里有无数的妹子语音和文字一一准确对应用作训练素材），只能说这个自训练思路也是个不错的方案。

但是我载预训练模型的过程中pypi包安装失败，简单搜索了一下似乎是python版本不兼容造成的，导致pyopenktalk这个包安装失败。大概看了一眼报错信息，盲猜是那类需要某某编译环境现场编译的包。因为win平台上编译本来就搞得很混乱，又是gcc又是msvc（可怕的是生态还能分庭抗礼。。）有时候出现类似问题也见惯不怪了。后面又翻到那个开源的项目用的是基于tensorflow的，我们本身OCR项目是基于torch的，音视频两个项目载入要把两个框架全都下一遍，属实是有点难顶，所以最后也就放弃了。